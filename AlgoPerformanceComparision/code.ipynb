{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_frame = pd.read_csv('breast-cancer-wisconsin.data')\n",
    "data_frame = data_frame.apply(pd.to_numeric, errors='coerce')\n",
    "data_frame = data_frame.fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = data_frame.copy()\n",
    "for data in normalized_data:\n",
    "    max_value = data_frame[data].max()\n",
    "    min_value = data_frame[data].min() \n",
    "    normalized_data[data] = (normalized_data[data]-min_value)/(max_value-min_value)\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "# Performed K-Nearest Neighbour\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X = normalized_data.iloc[:, :-1]  \n",
    "y = normalized_data.iloc[:, -1]  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "k = 5 \n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on Test Data:\", accuracy)\n",
    "\n",
    "# actual_vs_predicted = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "# print(\"\\nActual vs. Predicted Values:\")\n",
    "# print(actual_vs_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Perform Univariate Trees\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = normalized_data.iloc[:, :-1]  \n",
    "y = normalized_data.iloc[:, -1]  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = normalized_data.iloc[:, :-1]  \n",
    "y = normalized_data.iloc[:, -1]  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassified samples\n",
      "Sample 71: True Class - 0.0, Predicted Class - 1.0\n",
      "Sample 109: True Class - 0.0, Predicted Class - 1.0\n",
      "Sample 118: True Class - 0.0, Predicted Class - 1.0\n",
      "Confusion Matrix for K-Nearest Neighbors:\n",
      "[[86  3]\n",
      " [ 0 51]]\n",
      "\n",
      "Confusion Matrix for Decision Tree Classifier:\n",
      "[[86  3]\n",
      " [ 5 46]]\n",
      "\n",
      "Confusion Matrix for Gaussian Naive Bayes Classifier:\n",
      "[[85  4]\n",
      " [ 0 51]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = normalized_data.iloc[:, :-1].values  \n",
    "y = normalized_data.iloc[:, -1].values   \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = DecisionTreeClassifier()\n",
    "gnb = GaussianNB()\n",
    "\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Create lists to store misclassified samples for each classifier\n",
    "misclassified_samples_knn = []\n",
    "misclassified_samples_tree = []\n",
    "misclassified_samples_gnb = []\n",
    "\n",
    "# Loop through test samples and classifiers\n",
    "for idx, (test_sample, true_class) in enumerate(zip(X_test, y_test)):\n",
    "    # K-Nearest Neighbors (KNN)\n",
    "    test_sample = np.array(test_sample).reshape(1, -1)  # Reshape the input data\n",
    "    predicted_class_knn = knn_classifier.predict(test_sample)[0]\n",
    "    if predicted_class_knn != true_class:\n",
    "        misclassified_samples_knn.append((idx, true_class, predicted_class_knn))\n",
    "\n",
    "    # Decision Tree Classifier\n",
    "    test_sample = np.array(test_sample).reshape(1, -1)  # Reshape the input data\n",
    "    predicted_class_tree = clf.predict(test_sample)[0]\n",
    "    if predicted_class_tree != true_class:\n",
    "        misclassified_samples_tree.append((idx, true_class, predicted_class_tree))\n",
    "\n",
    "    # Gaussian Naive Bayes Classifier\n",
    "    test_sample = np.array(test_sample).reshape(1, -1)  # Reshape the input data\n",
    "    predicted_class_gnb = gnb.predict(test_sample)[0]\n",
    "    if predicted_class_gnb != true_class:\n",
    "        misclassified_samples_gnb.append((idx, true_class, predicted_class_gnb))\n",
    "\n",
    "# Find samples misclassified by all classifiers\n",
    "misclassified_by_all = []\n",
    "for sample_knn in misclassified_samples_knn:\n",
    "    for sample_tree in misclassified_samples_tree:\n",
    "        for sample_gnb in misclassified_samples_gnb:\n",
    "            if (\n",
    "                sample_knn[0] == sample_tree[0] == sample_gnb[0] and\n",
    "                sample_knn[1] == sample_tree[1] == sample_gnb[1] and\n",
    "                sample_knn[2] == sample_tree[2] == sample_gnb[2]\n",
    "            ):\n",
    "                misclassified_by_all.append(sample_knn)\n",
    "\n",
    "# Prepare a report of misclassified samples by all classifiers\n",
    "print(\"misclassified samples\")\n",
    "for idx, true_class, predicted_class in misclassified_by_all:\n",
    "    print(f\"Sample {idx}: True Class - {true_class}, Predicted Class - {predicted_class}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix for K-Nearest Neighbors\n",
    "cm_knn = confusion_matrix(y_test, knn_classifier.predict(X_test))\n",
    "print(\"Confusion Matrix for K-Nearest Neighbors:\")\n",
    "print(cm_knn)\n",
    "\n",
    "# Calculate confusion matrix for Decision Tree Classifier\n",
    "cm_tree = confusion_matrix(y_test, clf.predict(X_test))\n",
    "print(\"\\nConfusion Matrix for Decision Tree Classifier:\")\n",
    "print(cm_tree)\n",
    "\n",
    "# Calculate confusion matrix for Gaussian Naive Bayes Classifier\n",
    "cm_gnb = confusion_matrix(y_test, gnb.predict(X_test))\n",
    "print(\"\\nConfusion Matrix for Gaussian Naive Bayes Classifier:\")\n",
    "print(cm_gnb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
